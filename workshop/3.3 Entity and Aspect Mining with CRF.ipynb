{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supervised Learning for Entity and Aspect Mining\n",
    "\n",
    "This notebook introduces Conditional Random Fields (CRF) for entity and aspect mining. Recall that we have mentioned that entity and aspect mining involves 3 main tasks:\n",
    "1. Extraction of entity \n",
    "2. Extraction of aspects associated with the entity\n",
    "3. Sentiment classification\n",
    "In this notebook, we use CRF for the second task. \n",
    "\n",
    "### Conditional Random Fields\n",
    "CRF is a sequence machine learning technique and is very popular in natural language porcessing (NLP). It is used for eg in Named entity Recogition (NER), Part of speech tagging (POS) and word sense disambiguation. \n",
    "\n",
    "The CRF is a subset of HMF (hidden markov fields) in that it may have dependencies beyond the adjacent words.\n",
    "\n",
    "Earlier, we had introduced several heuristic techniques for extraction of aspects. These include using dependency parsing, looking at syntactic relations (like 'of', 'from' etc). These rules can be integrated into the ML model - left as an exercise. For illustration we just use POS as features in this notebook. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding CRF in NLP \n",
    "\n",
    "The CRF is a sequential ML technique. By sequence, it means it is used to predict what's next in a sequence? For eg, in the entity and aspect mining perspective, ABSA -  aspect based sentiment analysis. \n",
    "\n",
    "Suppose $(\\bf{X},\\bf{Y})$ is a conditional random field such that Y are the observables and X is a latent variable. In NLP, Y can be the actual words themselves - 'like', 'of', 'and' etc. while X are the POS tags - which need to be derived through an algorithm. In a CRF:\n",
    "\n",
    "$\n",
    " p(Y_v \\vert X, Y_w, w\\ne v) =  p(Y_v \\vert X, Y_w, w \\sim v)\n",
    "$\n",
    "\n",
    "Here $\\sim$ refers to the surrounding words. CRF is a specific case of MRF where the latter refers to the immediate instead of surrounding words. Note this expression is a conditional probability which is computed by Bayes rule from the learning corpus. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.21.3\n"
     ]
    }
   ],
   "source": [
    "from itertools import chain\n",
    "import nltk\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "import pycrfsuite  # crf\n",
    "\n",
    "print(sklearn.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our training data set needs to be labelled and obtained from the CoNLL 2003 dataset. https://www.aclweb.org/anthology/W03-0419 It is in a iob format. It essentially contains 3 columns. The first column is the actual words, the second is the POS and the 3rd column where it is an entity B-A, aspect I-A or others O. We write a simple code to convert it into a form to use the pycrfsuite library for CRF. This is the most accessible library to run CRFs. \n",
    "\n",
    "The function word2features extracts out features in the sentence - in this case just POS of the individual tokens. The function is adapted from https://sklearn-crfsuite.readthedocs.io/en/latest/tutorial.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 47.9 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "def createCRFSet(fname):\n",
    "    train_sents = []\n",
    "    tt_sents = []\n",
    "    t_sents = []\n",
    "    fp = open(fname,  encoding=\"utf-8\")\n",
    "   \n",
    "    for line in fp.readlines():\n",
    "        line = tuple(line.split())\n",
    "        t_sents.append(line)\n",
    "    \n",
    "    for t in t_sents:\n",
    "        if len(t)!=0: \n",
    "            tt_sents.append(t)\n",
    "        else:\n",
    "            train_sents.append(tt_sents)\n",
    "            tt_sents=[]\n",
    "    \n",
    "    return train_sents\n",
    "\n",
    "train_sents = createCRFSet(\"data/Restaurants_Train.iob\")\n",
    "test_sents = createCRFSet(\"data/Restaurants_Test.iob\")\n",
    "#test_sents = list(nltk.corpus.conll2002.iob_sents('esp.testb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word2features(sent, i):\n",
    "    word = sent[i][0]\n",
    "    postag = sent[i][1]\n",
    "    features = [  # for all words\n",
    "        'bias',\n",
    "        'postag=' + postag,\n",
    "      #  'word.lower()': word.lower(),\n",
    "        #'word[-3:]': word[-3:],\n",
    "       # 'word[-2:]': word[-2:],\n",
    "        #'word.isupper()': word.isupper(),\n",
    "        #'word.istitle()': word.istitle(),\n",
    "        #'word.isdigit()': word.isdigit(),\n",
    "        #'postag[:2]': postag[:2],\n",
    "    ]\n",
    "    if i > 0: # if BOS(beginning of statement)\n",
    "        word1 = sent[i-1][0]\n",
    "        postag1 = sent[i-1][1]\n",
    "        features.extend([\n",
    "            '-1:postag=' + postag1\n",
    "            # '-1:word.lower()': word1.lower(),\n",
    "            #'-1:word.istitle()': word1.istitle(),\n",
    "            #'-1:word.isupper()': word1.isupper(),\n",
    "            #'-1:postag': postag1,\n",
    "            #'-1:postag[:2]': postag1[:2],\n",
    "        ])\n",
    "    else:\n",
    "        features.append('BOS')  # beginning of statement\n",
    "        \n",
    "    if i < len(sent)-1:  # if EOS(end of statement)\n",
    "        word1 = sent[i+1][0]\n",
    "        postag1 = sent[i+1][1]\n",
    "        features.extend([\n",
    "            '+1:postag=' + postag1\n",
    "            #'+1:word.lower()': word1.lower(),\n",
    "            #'+1:word.istitle()': word1.istitle(),\n",
    "            #'+1:word.isupper()': word1.isupper(),\n",
    "            #'+1:postag': postag1,\n",
    "            #'+1:postag[:2]': postag1[:2],\n",
    "        ])\n",
    "    else:\n",
    "        features.append('EOS')\n",
    "                \n",
    "    return features\n",
    "\n",
    "\n",
    "def sent2features(sent):\n",
    "    return [word2features(sent, i) for i in range(len(sent))]\n",
    "\n",
    "def sent2labels(sent):\n",
    "    return [label for token, postag, label in sent]\n",
    "\n",
    "def sent2tokens(sent):\n",
    "    return [token for token, postag, label in sent]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note the features for one of the sentence - 'To be completely fair, the only redeeming factor was the food which was above average, but couldn't make up for all the other deficiencies of Teodora'. The POS tags (before and after are used as features)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>POS</th>\n",
       "      <th>Entity or Aspect Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Not</td>\n",
       "      <td>RB</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>only</td>\n",
       "      <td>RB</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>was</td>\n",
       "      <td>VBD</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>the</td>\n",
       "      <td>DT</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>food</td>\n",
       "      <td>NN</td>\n",
       "      <td>B-A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>outstanding</td>\n",
       "      <td>JJ</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>but</td>\n",
       "      <td>CC</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>the</td>\n",
       "      <td>DT</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>little</td>\n",
       "      <td>JJ</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>'</td>\n",
       "      <td>POS</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>perks</td>\n",
       "      <td>NNS</td>\n",
       "      <td>B-A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>'</td>\n",
       "      <td>POS</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>were</td>\n",
       "      <td>VBD</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>great</td>\n",
       "      <td>JJ</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Word  POS Entity or Aspect Tag\n",
       "0           Not   RB                    O\n",
       "1          only   RB                    O\n",
       "2           was  VBD                    O\n",
       "3           the   DT                    O\n",
       "4          food   NN                  B-A\n",
       "5   outstanding   JJ                    O\n",
       "6             ,    ,                    O\n",
       "7           but   CC                    O\n",
       "8           the   DT                    O\n",
       "9        little   JJ                    O\n",
       "10            '  POS                    O\n",
       "11        perks  NNS                  B-A\n",
       "12            '  POS                    O\n",
       "13         were  VBD                    O\n",
       "14        great   JJ                    O\n",
       "15            .    .                    O"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_1 = pd.DataFrame(train_sents[5],columns=[\"Word\",\"POS\",\"Entity or Aspect Tag\"])\n",
    "# change to dataframe for easy printing.\n",
    "df_1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Bias constant</th>\n",
       "      <th>POS</th>\n",
       "      <th>POS Before</th>\n",
       "      <th>POS after</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bias</td>\n",
       "      <td>postag=TO</td>\n",
       "      <td>BOS</td>\n",
       "      <td>+1:postag=VB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bias</td>\n",
       "      <td>postag=VB</td>\n",
       "      <td>-1:postag=TO</td>\n",
       "      <td>+1:postag=RB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bias</td>\n",
       "      <td>postag=RB</td>\n",
       "      <td>-1:postag=VB</td>\n",
       "      <td>+1:postag=JJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bias</td>\n",
       "      <td>postag=JJ</td>\n",
       "      <td>-1:postag=RB</td>\n",
       "      <td>+1:postag=,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bias</td>\n",
       "      <td>postag=,</td>\n",
       "      <td>-1:postag=JJ</td>\n",
       "      <td>+1:postag=DT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>bias</td>\n",
       "      <td>postag=DT</td>\n",
       "      <td>-1:postag=,</td>\n",
       "      <td>+1:postag=JJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>bias</td>\n",
       "      <td>postag=JJ</td>\n",
       "      <td>-1:postag=DT</td>\n",
       "      <td>+1:postag=NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>bias</td>\n",
       "      <td>postag=NN</td>\n",
       "      <td>-1:postag=JJ</td>\n",
       "      <td>+1:postag=NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>bias</td>\n",
       "      <td>postag=NN</td>\n",
       "      <td>-1:postag=NN</td>\n",
       "      <td>+1:postag=VBD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>bias</td>\n",
       "      <td>postag=VBD</td>\n",
       "      <td>-1:postag=NN</td>\n",
       "      <td>+1:postag=DT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>bias</td>\n",
       "      <td>postag=DT</td>\n",
       "      <td>-1:postag=VBD</td>\n",
       "      <td>+1:postag=NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>bias</td>\n",
       "      <td>postag=NN</td>\n",
       "      <td>-1:postag=DT</td>\n",
       "      <td>+1:postag=,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>bias</td>\n",
       "      <td>postag=,</td>\n",
       "      <td>-1:postag=NN</td>\n",
       "      <td>+1:postag=WDT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>bias</td>\n",
       "      <td>postag=WDT</td>\n",
       "      <td>-1:postag=,</td>\n",
       "      <td>+1:postag=VBD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>bias</td>\n",
       "      <td>postag=VBD</td>\n",
       "      <td>-1:postag=WDT</td>\n",
       "      <td>+1:postag=IN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>bias</td>\n",
       "      <td>postag=IN</td>\n",
       "      <td>-1:postag=VBD</td>\n",
       "      <td>+1:postag=NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>bias</td>\n",
       "      <td>postag=NN</td>\n",
       "      <td>-1:postag=IN</td>\n",
       "      <td>+1:postag=,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>bias</td>\n",
       "      <td>postag=,</td>\n",
       "      <td>-1:postag=NN</td>\n",
       "      <td>+1:postag=CC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>bias</td>\n",
       "      <td>postag=CC</td>\n",
       "      <td>-1:postag=,</td>\n",
       "      <td>+1:postag=NNS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>bias</td>\n",
       "      <td>postag=NNS</td>\n",
       "      <td>-1:postag=CC</td>\n",
       "      <td>+1:postag=VBP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>bias</td>\n",
       "      <td>postag=VBP</td>\n",
       "      <td>-1:postag=NNS</td>\n",
       "      <td>+1:postag=RP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>bias</td>\n",
       "      <td>postag=RP</td>\n",
       "      <td>-1:postag=VBP</td>\n",
       "      <td>+1:postag=IN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>bias</td>\n",
       "      <td>postag=IN</td>\n",
       "      <td>-1:postag=RP</td>\n",
       "      <td>+1:postag=PDT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>bias</td>\n",
       "      <td>postag=PDT</td>\n",
       "      <td>-1:postag=IN</td>\n",
       "      <td>+1:postag=DT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>bias</td>\n",
       "      <td>postag=DT</td>\n",
       "      <td>-1:postag=PDT</td>\n",
       "      <td>+1:postag=JJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>bias</td>\n",
       "      <td>postag=JJ</td>\n",
       "      <td>-1:postag=DT</td>\n",
       "      <td>+1:postag=NNS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>bias</td>\n",
       "      <td>postag=NNS</td>\n",
       "      <td>-1:postag=JJ</td>\n",
       "      <td>+1:postag=IN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>bias</td>\n",
       "      <td>postag=IN</td>\n",
       "      <td>-1:postag=NNS</td>\n",
       "      <td>+1:postag=NNP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>bias</td>\n",
       "      <td>postag=NNP</td>\n",
       "      <td>-1:postag=IN</td>\n",
       "      <td>+1:postag=.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>bias</td>\n",
       "      <td>postag=.</td>\n",
       "      <td>-1:postag=NNP</td>\n",
       "      <td>EOS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Bias constant         POS     POS Before      POS after\n",
       "0           bias   postag=TO            BOS   +1:postag=VB\n",
       "1           bias   postag=VB   -1:postag=TO   +1:postag=RB\n",
       "2           bias   postag=RB   -1:postag=VB   +1:postag=JJ\n",
       "3           bias   postag=JJ   -1:postag=RB    +1:postag=,\n",
       "4           bias    postag=,   -1:postag=JJ   +1:postag=DT\n",
       "5           bias   postag=DT    -1:postag=,   +1:postag=JJ\n",
       "6           bias   postag=JJ   -1:postag=DT   +1:postag=NN\n",
       "7           bias   postag=NN   -1:postag=JJ   +1:postag=NN\n",
       "8           bias   postag=NN   -1:postag=NN  +1:postag=VBD\n",
       "9           bias  postag=VBD   -1:postag=NN   +1:postag=DT\n",
       "10          bias   postag=DT  -1:postag=VBD   +1:postag=NN\n",
       "11          bias   postag=NN   -1:postag=DT    +1:postag=,\n",
       "12          bias    postag=,   -1:postag=NN  +1:postag=WDT\n",
       "13          bias  postag=WDT    -1:postag=,  +1:postag=VBD\n",
       "14          bias  postag=VBD  -1:postag=WDT   +1:postag=IN\n",
       "15          bias   postag=IN  -1:postag=VBD   +1:postag=NN\n",
       "16          bias   postag=NN   -1:postag=IN    +1:postag=,\n",
       "17          bias    postag=,   -1:postag=NN   +1:postag=CC\n",
       "18          bias   postag=CC    -1:postag=,  +1:postag=NNS\n",
       "19          bias  postag=NNS   -1:postag=CC  +1:postag=VBP\n",
       "20          bias  postag=VBP  -1:postag=NNS   +1:postag=RP\n",
       "21          bias   postag=RP  -1:postag=VBP   +1:postag=IN\n",
       "22          bias   postag=IN   -1:postag=RP  +1:postag=PDT\n",
       "23          bias  postag=PDT   -1:postag=IN   +1:postag=DT\n",
       "24          bias   postag=DT  -1:postag=PDT   +1:postag=JJ\n",
       "25          bias   postag=JJ   -1:postag=DT  +1:postag=NNS\n",
       "26          bias  postag=NNS   -1:postag=JJ   +1:postag=IN\n",
       "27          bias   postag=IN  -1:postag=NNS  +1:postag=NNP\n",
       "28          bias  postag=NNP   -1:postag=IN    +1:postag=.\n",
       "29          bias    postag=.  -1:postag=NNP            EOS"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2 = pd.DataFrame(sent2features(train_sents[1]), columns=[\"Bias constant\",\"POS\",\"POS Before\",\"POS after\"])  #bias content is the content(just ike the 'c'in regression)偏置\n",
    "df_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('To', 'TO', 'O'),\n",
       " ('be', 'VB', 'O'),\n",
       " ('completely', 'RB', 'O'),\n",
       " ('fair', 'JJ', 'O'),\n",
       " (',', ',', 'O'),\n",
       " ('the', 'DT', 'O'),\n",
       " ('only', 'JJ', 'O'),\n",
       " ('redeeming', 'NN', 'O'),\n",
       " ('factor', 'NN', 'O'),\n",
       " ('was', 'VBD', 'O'),\n",
       " ('the', 'DT', 'O'),\n",
       " ('food', 'NN', 'B-A'),\n",
       " (',', ',', 'O'),\n",
       " ('which', 'WDT', 'O'),\n",
       " ('was', 'VBD', 'O'),\n",
       " ('above', 'IN', 'O'),\n",
       " ('average', 'NN', 'O'),\n",
       " (',', ',', 'O'),\n",
       " ('but', 'CC', 'O'),\n",
       " (\"couldn't\", 'NNS', 'O'),\n",
       " ('make', 'VBP', 'O'),\n",
       " ('up', 'RP', 'O'),\n",
       " ('for', 'IN', 'O'),\n",
       " ('all', 'PDT', 'O'),\n",
       " ('the', 'DT', 'O'),\n",
       " ('other', 'JJ', 'O'),\n",
       " ('deficiencies', 'NNS', 'O'),\n",
       " ('of', 'IN', 'O'),\n",
       " ('Teodora', 'NNP', 'O'),\n",
       " ('.', '.', 'O')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sents[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 79.8 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_train = [sent2features(s) for s in train_sents]\n",
    "y_train = [sent2labels(s) for s in train_sents]\n",
    "\n",
    "X_test = [sent2features(s) for s in test_sents]\n",
    "y_test = [sent2labels(s) for s in test_sents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Where', 'WRB', 'O'),\n",
       " ('Gabriela', 'NNP', 'O'),\n",
       " ('personaly', 'VBZ', 'O'),\n",
       " ('greets', 'NNS', 'O'),\n",
       " ('you', 'PRP', 'O'),\n",
       " ('and', 'CC', 'O'),\n",
       " ('recommends', 'VB', 'O'),\n",
       " ('you', 'PRP', 'O'),\n",
       " ('what', 'WP', 'O'),\n",
       " ('to', 'TO', 'O'),\n",
       " ('eat', 'VB', 'O'),\n",
       " ('.', '.', 'O')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sents[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 70.8 ms\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%%time\n",
    "trainer = pycrfsuite.Trainer(verbose=False)\n",
    "\n",
    "for xseq, yseq in zip(X_train, y_train):\n",
    "    trainer.append(xseq, yseq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "trainer.set_params({\n",
    "    'c1': 1.0,   # coefficient for L1 penalty(减少Overfitting)\n",
    "    'c2': 1e-3,  # coefficient for L2 penalty\n",
    "    'max_iterations': 50,  # stop earlier\n",
    "\n",
    "    # include transitions that are possible, but not observed\n",
    "    'feature.possible_transitions': True\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['feature.minfreq',\n",
       " 'feature.possible_states',\n",
       " 'feature.possible_transitions',\n",
       " 'c1',\n",
       " 'c2',\n",
       " 'max_iterations',\n",
       " 'num_memories',\n",
       " 'epsilon',\n",
       " 'period',\n",
       " 'delta',\n",
       " 'linesearch',\n",
       " 'max_linesearch']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 359 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Here we save the trained CRF model. \n",
    "trainer.train('CRF_ABSA.crfsuite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'num': 50,\n",
       " 'scores': {},\n",
       " 'loss': 8270.838023,\n",
       " 'feature_norm': 16.557075,\n",
       " 'error_norm': 161.739801,\n",
       " 'active_features': 241,\n",
       " 'linesearch_trials': 1,\n",
       " 'linesearch_step': 1.0,\n",
       " 'time': 0.007}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.logparser.last_iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 {'num': 50, 'scores': {}, 'loss': 8270.838023, 'feature_norm': 16.557075, 'error_norm': 161.739801, 'active_features': 241, 'linesearch_trials': 1, 'linesearch_step': 1.0, 'time': 0.007}\n"
     ]
    }
   ],
   "source": [
    "print (len(trainer.logparser.iterations), trainer.logparser.iterations[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<contextlib.closing at 0x20cd4f7a2e8>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagger = pycrfsuite.Tagger()\n",
    "tagger.open('CRF_ABSA.crfsuite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I trust the people at Go Sushi , it never disappoints .\n",
      "\n",
      "Predicted: O O O O O O O O O O O O\n",
      "Correct:   O O O B-A O O O O O O O O\n"
     ]
    }
   ],
   "source": [
    "\n",
    "example_sent = test_sents[5]\n",
    "print(' '.join(sent2tokens(example_sent)), end='\\n\\n')\n",
    "\n",
    "print(\"Predicted:\", ' '.join(tagger.tag(sent2features(example_sent))))\n",
    "print(\"Correct:  \", ' '.join(sent2labels(example_sent)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bio_classification_report(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Classification report for a list of BIO-encoded sequences.\n",
    "    It computes token-level metrics and discards \"O\" labels.\n",
    "    \n",
    "    Note that it requires scikit-learn 0.15+ (or a version from github master)\n",
    "    to calculate averages properly!\n",
    "    \"\"\"\n",
    "    lb = LabelBinarizer()\n",
    "    y_true_combined = lb.fit_transform(list(chain.from_iterable(y_true)))\n",
    "    y_pred_combined = lb.transform(list(chain.from_iterable(y_pred)))\n",
    "        \n",
    "    tagset = set(lb.classes_) - {'O'}\n",
    "    tagset = sorted(tagset, key=lambda tag: tag.split('-', 1)[::-1])\n",
    "    class_indices = {cls: idx for idx, cls in enumerate(lb.classes_)}\n",
    "    \n",
    "    return classification_report(\n",
    "        y_true_combined,\n",
    "        y_pred_combined,\n",
    "        labels = [class_indices[cls] for cls in tagset],\n",
    "        target_names = tagset,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 17.9 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_pred = [tagger.tag(xseq) for xseq in X_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         B-A       0.62      0.36      0.46      1135\n",
      "         I-A       0.55      0.23      0.32       538\n",
      "\n",
      "   micro avg       0.60      0.32      0.42      1673\n",
      "   macro avg       0.59      0.30      0.39      1673\n",
      "weighted avg       0.60      0.32      0.41      1673\n",
      " samples avg       0.04      0.04      0.04      1673\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\isstyc\\AppData\\Local\\Continuum\\anaconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\isstyc\\AppData\\Local\\Continuum\\anaconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\metrics\\classification.py:1439: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print(bio_classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The CRF theory is such that there are transiting hidden states - some of which are more probable than others. The below shows that is B-A -> I-A is very likely. An example of this is iPhone (B-A) size (I-A). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top likely transitions:\n",
      "I-A    -> I-A     2.657962\n",
      "B-A    -> I-A     2.559635\n",
      "O      -> O       1.920100\n",
      "O      -> B-A     1.000955\n",
      "B-A    -> O       0.152442\n",
      "NN     -> B-A     -0.244032\n",
      "I-A    -> O       -0.658764\n",
      "O      -> NN      -0.980371\n",
      "\n",
      "Top unlikely transitions:\n",
      "B-A    -> O       0.152442\n",
      "NN     -> B-A     -0.244032\n",
      "I-A    -> O       -0.658764\n",
      "O      -> NN      -0.980371\n",
      "NN     -> O       -2.090161\n",
      "I-A    -> B-A     -4.247481\n",
      "B-A    -> B-A     -5.006722\n",
      "O      -> I-A     -6.641027\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from collections import Counter\n",
    "info = tagger.info()\n",
    "\n",
    "def print_transitions(trans_features):\n",
    "    for (label_from, label_to), weight in trans_features:\n",
    "        print(\"%-6s -> %-7s %0.6f\" % (label_from, label_to, weight))\n",
    "\n",
    "print(\"Top likely transitions:\")\n",
    "print_transitions(Counter(info.transitions).most_common(8))\n",
    "\n",
    "print(\"\\nTop unlikely transitions:\")\n",
    "print_transitions(Counter(info.transitions).most_common()[-8:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which feature is the most common (or least common) to tag entities or aspects. In the below, in particular to positively tag aspects it is the feature -1:postag=PRP - that is if the word before is a preposition word. This includes words like 'of', 'in', 'at' etc. Makes sense of the heuristic rules earlier mentioned!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top positive:\n",
      "3.756987 O      postag=,\n",
      "3.561562 O      postag=PRP\n",
      "3.432838 O      postag=.\n",
      "2.797307 O      postag=WDT\n",
      "2.301108 O      postag=PRP$\n",
      "2.278891 O      EOS\n",
      "2.209918 O      BOS\n",
      "1.866367 I-A    -1:postag=PRP\n",
      "1.826179 I-A    postag=SYM\n",
      "1.767864 O      +1:postag=CD\n",
      "1.727703 O      postag=JJS\n",
      "1.655197 O      postag=WP\n",
      "1.535133 O      bias\n",
      "1.472674 B-A    postag=NN\n",
      "1.412390 B-A    postag=NNS\n",
      "1.379069 NN     postag=.\n",
      "1.361568 NN     EOS\n",
      "1.342975 I-A    postag=NN\n",
      "1.224582 B-A    BOS\n",
      "1.190439 O      postag=VBZ\n"
     ]
    }
   ],
   "source": [
    "def print_state_features(state_features):\n",
    "    for (attr, label), weight in state_features:\n",
    "        print(\"%0.6f %-6s %s\" % (weight, label, attr))    \n",
    "\n",
    "print(\"Top positive:\")\n",
    "print_state_features(Counter(info.state_features).most_common(20))\n",
    "\n",
    "#rint(\"\\nTop negative:\")\n",
    "#print_state_features(Counter(info.state_features).most_common()[-20:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
